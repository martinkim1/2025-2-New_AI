from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# .env 파일에서 환경 변수를 로드합니다.
load_dotenv()
# prompt + model + output parser
prompt = ChatPromptTemplate.from_template("You are an expert in astronomy. Answer the question. <Question>: {input}")
llm = ChatOpenAI(model="gpt-4o-mini")
output_parser = StrOutputParser()
# LCEL chaining
chain = prompt | llm | output_parser
# chain 호출
response = chain.invoke({"input": "지구의 자전 주기는?"})
print(response)
